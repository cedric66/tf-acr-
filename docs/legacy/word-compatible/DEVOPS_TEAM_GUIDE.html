<!DOCTYPE html>
<html><head><meta charset="UTF-8">
<style>
body { font-family: "Calibri", "Arial", sans-serif; font-size: 11pt; line-height: 1.5; color: #000; max-width: 800px; margin: 20px auto; }
h1 { font-size: 24pt; color: #2E74B5; border-bottom: 2px solid #2E74B5; padding-bottom: 10px; margin-top: 24pt; }
h2 { font-size: 18pt; color: #2E74B5; margin-top: 18pt; }
h3 { font-size: 14pt; color: #1F4D78; margin-top: 14pt; }
h4 { font-size: 12pt; font-weight: bold; margin-top: 12pt; }
p { margin-bottom: 10pt; }
ul, ol { margin-bottom: 10pt; }
li { margin-bottom: 4pt; }
pre { font-family: "Consolas", "Courier New", monospace; font-size: 10pt; background-color: #f5f5f5; padding: 10px; border: 1px solid #ddd; white-space: pre-wrap; word-wrap: break-word; }
code { font-family: "Consolas", "Courier New", monospace; color: #c7254e; background-color: #f9f2f4; padding: 2px 4px; border-radius: 4px; }
pre code { background-color: transparent; color: inherit; padding: 0; }
.mermaid { border: 1px solid #007acc; background-color: #e6f7ff; padding: 15px; border-radius: 5px; margin: 10px 0; }
.mermaid-title { color: #007acc; font-weight: bold; font-family: sans-serif; margin-bottom: 5px; }
table { border-collapse: collapse; width: 100%; margin-bottom: 15px; }
th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
th { background-color: #f2f2f2; color: #333; }
blockquote { border-left: 4px solid #ddd; padding-left: 15px; color: #666; font-style: italic; }
</style>
</head><body>
<h1>DevOps Team Guide: Deploying on AKS with Spot Nodes</h1>
<p><b>Audience:</b> Application Development Teams, DevOps Engineers  </p>
<p><b>Purpose:</b> Enable teams to deploy cost-optimized workloads on spot instances  </p>
<p><b>Created:</b> 2026-01-12</p>
<p>---</p>
<h2>Quick Start</h2>
<h3>Can My Application Run on Spot?</h3>
<p><b>Use this decision tree:</b></p>
<pre class=""><code>
Start

├─ Is your app stateful (database, cache with persistence)?

│  └─ YES → ❌ Do NOT use spot

│  └─ NO → Continue

│

├─ Can your app tolerate sudden termination (30-sec warning)?

│  └─ NO → ❌ Do NOT use spot

│  └─ YES → Continue

│

├─ Does your app handle PCI/HIPAA/SOC2 data?

│  └─ YES → ❌ Do NOT use spot (compliance requirement)

│  └─ NO → Continue

│

└─ ✅ Your app is SPOT-ELIGIBLE!

</code></pre>
<p><b>Examples:</b></p>
<table>
<tr><td>Workload Type</td><td>Spot Eligible?</td><td>Reasoning</td></tr>
<tr><td>REST API (stateless)</td><td>✅ Yes</td><td>No local state, terminates cleanly</td></tr>
<tr><td>Web Frontend</td><td>✅ Yes</td><td>Stateless, multiple replicas</td></tr>
<tr><td>Background Job Worker</td><td>✅ Yes</td><td>Resumable, queue-based</td></tr>
<tr><td>Batch Processing</td><td>✅ Yes</td><td>Checkpointed, can resume</td></tr>
<tr><td>CI/CD Runner</td><td>✅ Yes</td><td>Ephemeral by design</td></tr>
<tr><td>Redis (cache-only, no persistence)</td><td>⚠️ Maybe</td><td>If cache miss is acceptable</td></tr>
<tr><td>PostgreSQL Database</td><td>❌ No</td><td>Stateful, critical data</td></tr>
<tr><td>Kafka Broker</td><td>❌ No</td><td>Stateful, leader election</td></tr>
<tr><td>Payment Service (PCI-DSS)</td><td>❌ No</td><td>Compliance requirement</td></tr>
</table>
<p>---</p>
<h2>Deploying to Spot Nodes</h2>
<h3>Method 1: Just Add Tolerations (Simple)</h3>
<p>Add this to your existing deployment:</p>
<pre class="yaml"><code>
apiVersion: apps/v1

kind: Deployment

metadata:

  name: my-api

spec:

  replicas: 3

  template:

    spec:

      # ADD THIS: Allow scheduling on spot nodes

      tolerations:

        - key: kubernetes.azure.com/scalesetpriority

          operator: Equal

          value: spot

          effect: NoSchedule



      containers:

        - name: api

          image: myapp:v1.0

          # ... rest of your config

</code></pre>
<p><b>What this does:</b></p>
<ul>
<li>Your pods CAN schedule on spot nodes</li>
<li>They will PREFER spot nodes (cheaper)</li>
<li>They will FALL BACK to standard nodes if spot unavailable</li>
</ul>
<p><b>When to use:</b> Quick wins, dev/test environments</p>
<p>---</p>
<h3>Method 2: Full Optimization (Recommended for Production)</h3>
<p>Use this complete template for production applications:</p>
<pre class="yaml"><code>
apiVersion: apps/v1

kind: Deployment

metadata:

  name: my-api

  labels:

    app: my-api

    cost-optimization: spot-preferred

spec:

  replicas: 6  # Use 3+ replicas for spot workloads



  strategy:

    type: RollingUpdate

    rollingUpdate:

      maxSurge: 25%

      maxUnavailable: 25%



  selector:

    matchLabels:

      app: my-api



  template:

    metadata:

      labels:

        app: my-api



    spec:

      ##################################################################

      # SPOT CONFIGURATION

      ##################################################################



      # 1. TOLERATION: Allow scheduling on spot nodes

      tolerations:

        - key: kubernetes.azure.com/scalesetpriority

          operator: Equal

          value: spot

          effect: NoSchedule



        # Tolerate brief node unavailability during eviction

        - key: node.kubernetes.io/not-ready

          operator: Exists

          effect: NoExecute

          tolerationSeconds: 30



        - key: node.kubernetes.io/unreachable

          operator: Exists

          effect: NoExecute

          tolerationSeconds: 30



      # 2. AFFINITY: Prefer spot, fall back to standard

      affinity:

        nodeAffinity:

          preferredDuringSchedulingIgnoredDuringExecution:

            # Highest priority: Prefer spot nodes (cost savings)

            - weight: 100

              preference:

                matchExpressions:

                  - key: kubernetes.azure.com/scalesetpriority

                    operator: In

                    values: [spot]

            # Lower priority: Fall back to standard nodes

            - weight: 50

              preference:

                matchExpressions:

                  - key: priority

                    operator: In

                    values: [on-demand]



        # Spread pods across different nodes for HA

        podAntiAffinity:

          preferredDuringSchedulingIgnoredDuringExecution:

            - weight: 100

              podAffinityTerm:

                labelSelector:

                  matchExpressions:

                    - key: app

                      operator: In

                      values: [my-api]

                topologyKey: kubernetes.io/hostname



      # 3. TOPOLOGY SPREAD: Distribute pods for resilience

      topologySpreadConstraints:

        # Spread across availability zones

        - maxSkew: 1

          topologyKey: topology.kubernetes.io/zone

          whenUnsatisfiable: ScheduleAnyway  # Don&#x27;t block scheduling

          labelSelector:

            matchLabels:

              app: my-api



        # Spread across node pool types (spot vs standard)

        - maxSkew: 2  # Allow some imbalance to prefer spot

          topologyKey: kubernetes.azure.com/scalesetpriority

          whenUnsatisfiable: ScheduleAnyway

          labelSelector:

            matchLabels:

              app: my-api



        # Spread across individual nodes

        - maxSkew: 1

          topologyKey: kubernetes.io/hostname

          whenUnsatisfiable: ScheduleAnyway

          labelSelector:

            matchLabels:

              app: my-api



      ##################################################################

      # GRACEFUL SHUTDOWN (CRITICAL FOR SPOT!)

      ##################################################################



      containers:

        - name: api

          image: myapp:v1.0



          ports:

            - name: http

              containerPort: 8080



          # Health checks (mark pod NotReady before shutdown)

          readinessProbe:

            httpGet:

              path: /health/ready

              port: http

            periodSeconds: 5

            failureThreshold: 2  # Fast to mark NotReady



          livenessProbe:

            httpGet:

              path: /health/live

              port: http

            periodSeconds: 10



          # CRITICAL: Graceful shutdown handler

          lifecycle:

            preStop:

              exec:

                command:

                  - /bin/sh

                  - -c

                  - |

                    echo &quot;Received shutdown signal - starting graceful shutdown&quot;

                    # Stop accepting new connections

                    kill -TERM 1 2&gt;/dev/null || true

                    # Wait for existing connections to complete

                    sleep 25

                    echo &quot;Graceful shutdown complete&quot;



          env:

            - name: SHUTDOWN_TIMEOUT_SECONDS

              value: &quot;30&quot;



          resources:

            requests:

              cpu: 250m

              memory: 256Mi

            limits:

              cpu: 1000m

              memory: 1Gi



      # Pod shutdown grace period (must be &gt;= preStop sleep time)

      terminationGracePeriodSeconds: 35



      # Security context

      securityContext:

        runAsNonRoot: true

        runAsUser: 1000



---

# Pod Disruption Budget - Ensure minimum availability

apiVersion: policy/v1

kind: PodDisruptionBudget

metadata:

  name: my-api-pdb

spec:

  minAvailable: 50%  # At least half your pods must remain available

  selector:

    matchLabels:

      app: my-api

</code></pre>
<p><b>When to use:</b> Production workloads, high availability requirements</p>
<p>---</p>
<h2>Application Code Changes</h2>
<h3>Implementing Graceful Shutdown</h3>
<p>Your application MUST handle shutdown gracefully. Here's how:</p>
<h4>Node.js Example</h4>
<pre class="javascript"><code>
// server.js

const express = require(&#x27;express&#x27;);

const app = express();

const server = app.listen(8080);



// Health check endpoint

app.get(&#x27;/health/ready&#x27;, (req, res) =&gt; {

  if (shuttingDown) {

    return res.status(503).send(&#x27;Shutting down&#x27;);

  }

  res.status(200).send(&#x27;OK&#x27;);

});



let shuttingDown = false;



// Graceful shutdown handler

process.on(&#x27;SIGTERM&#x27;, () =&gt; {

  console.log(&#x27;SIGTERM received, starting graceful shutdown&#x27;);

  shuttingDown = true;  // Mark as NotReady



  // Stop accepting new connections

  server.close(() =&gt; {

    console.log(&#x27;HTTP server closed&#x27;);



    // Clean up resources (close DB connections, etc.)

    cleanupResources().then(() =&gt; {

      console.log(&#x27;Graceful shutdown complete&#x27;);

      process.exit(0);

    });

  });



  // Force shutdown after 30 seconds

  setTimeout(() =&gt; {

    console.error(&#x27;Forced shutdown after timeout&#x27;);

    process.exit(1);

  }, 30000);

});



async function cleanupResources() {

  // Close database connections

  await db.close();

  // Flush metrics

  await metrics.flush();

  // Any other cleanup

}

</code></pre>
<h4>Python (Flask) Example</h4>
<pre class="python"><code>
# app.py

from flask import Flask

import signal

import sys

import time



app = Flask(__name__)

shutting_down = False



@app.route(&#x27;/health/ready&#x27;)

def health_ready():

    if shutting_down:

        return &#x27;Shutting down&#x27;, 503

    return &#x27;OK&#x27;, 200



def graceful_shutdown(signum, frame):

    global shutting_down

    print(f&#x27;Signal {signum} received, starting graceful shutdown&#x27;)

    shutting_down = True  # Mark as NotReady



    # Give time for load balancer to remove this pod

    time.sleep(2)



    # Stop accepting new requests

    # Flask will finish current requests



    # Cleanup

    cleanup_resources()



    print(&#x27;Graceful shutdown complete&#x27;)

    sys.exit(0)



def cleanup_resources():

    # Close database connections

    db.close()

    # Flush logs

    logger.flush()



# Register signal handlers

signal.signal(signal.SIGTERM, graceful_shutdown)

signal.signal(signal.SIGINT, graceful_shutdown)



if __name__ == &#x27;__main__&#x27;:

    app.run(host=&#x27;0.0.0.0&#x27;, port=8080)

</code></pre>
<h4>Go Example</h4>
<pre class="go"><code>
// main.go

package main



import (

    &quot;context&quot;

    &quot;net/http&quot;

    &quot;os&quot;

    &quot;os/signal&quot;

    &quot;syscall&quot;

    &quot;time&quot;

)



var shuttingDown bool



func main() {

    mux := http.NewServeMux()



    // Health check

    mux.HandleFunc(&quot;/health/ready&quot;, func(w http.ResponseWriter, r *http.Request) {

        if shuttingDown {

            w.WriteHeader(http.StatusServiceUnavailable)

            return

        }

        w.WriteHeader(http.StatusOK)

    })



    server := &amp;http.Server{

        Addr:    &quot;:8080&quot;,

        Handler: mux,

    }



    // Start server in goroutine

    go func() {

        if err := server.ListenAndServe(); err != http.ErrServerClosed {

            log.Fatal(err)

        }

    }()



    // Wait for interrupt signal

    quit := make(chan os.Signal, 1)

    signal.Notify(quit, syscall.SIGTERM, syscall.SIGINT)

    &lt;-quit



    log.Println(&quot;Shutdown signal received, starting graceful shutdown&quot;)

    shuttingDown = true



    // Give load balancer time to remove pod from rotation

    time.Sleep(2 * time.Second)



    // Gracefully shutdown with 30-second timeout

    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)

    defer cancel()



    if err := server.Shutdown(ctx); err != nil {

        log.Printf(&quot;Server forced to shutdown: %v&quot;, err)

    }



    // Cleanup resources

    cleanupResources()



    log.Println(&quot;Graceful shutdown complete&quot;)

}



func cleanupResources() {

    // Close database connections

    db.Close()

    // Flush metrics

    metrics.Flush()

}

</code></pre>
<p>---</p>
<h2>Testing Your Application on Spot</h2>
<h3>Dev Environment Testing</h3>
<pre class="bash"><code>
# 1. Deploy your app to dev cluster (has spot nodes)

kubectl apply -f deployment.yaml --namespace=dev



# 2. Verify pods are on spot nodes

kubectl get pods -n dev -l app=my-api -o wide



# 3. Simulate eviction (drain a spot node)

SPOT_NODE=$(kubectl get nodes -l kubernetes.azure.com/scalesetpriority=spot -o name | head -1)

kubectl drain $SPOT_NODE --ignore-daemonsets --delete-emptydir-data



# 4. Watch pods reschedule

kubectl get pods -n dev -l app=my-api -w



# 5. Verify no downtime (run concurrent load test)

while true; do curl http://my-api-dev.company.com/health; sleep 0.5; done



# 6. Uncordon node when done testing

kubectl uncordon $SPOT_NODE

</code></pre>
<p><b>Expected Results:</b></p>
<ul>
<li>✅ Pods reschedule to other nodes within 30 seconds</li>
<li>✅ Zero or minimal failed requests during drain</li>
<li>✅ Application remains healthy throughout</li>
</ul>
<p>---</p>
<h2>Common Issues & Solutions</h2>
<h3>Issue 1: Pods Won't Schedule on Spot</h3>
<p><b>Symptom:</b> Pods always land on standard nodes, never spot</p>
<p><b>Diagnosis:</b></p>
<pre class="bash"><code>
kubectl describe pod &lt;pod-name&gt; | grep -A10 Events

</code></pre>
<p><b>Common Causes:</b></p>
<h4>Missing Toleration</h4>
<p><b>Fix:</b></p>
<pre class="yaml"><code>
tolerations:

  - key: kubernetes.azure.com/scalesetpriority

    value: spot

    effect: NoSchedule

</code></pre>
<h4>PodDisruptionBudget Too Restrictive</h4>
<p><b>Fix:</b> Adjust minAvailable to allow spot scheduling:</p>
<pre class="yaml"><code>
minAvailable: 1  # Instead of high number

</code></pre>
<h4>Resource Requests Too Large</h4>
<p><b>Fix:</b> Spot nodes might be smaller VM sizes. Reduce requests:</p>
<pre class="yaml"><code>
resources:

  requests:

    cpu: 250m      # Instead of 2000m

    memory: 256Mi  # Instead of 4Gi

</code></pre>
<p>---</p>
<h3>Issue 2: High Pod Churn (Frequent Rescheduling)</h3>
<p><b>Symptom:</b> Pods restarting frequently, event log shows many evictions</p>
<p><b>Diagnosis:</b></p>
<pre class="bash"><code>
kubectl get events -n &lt;namespace&gt; --sort-by=&#x27;.lastTimestamp&#x27; | grep Evicted

</code></pre>
<p><b>Possible Causes:</b></p>
<ol>
<li><b>Spot eviction rate is high</b> (external factor)</li>
<ul>
<li>Check SRE team for cluster-wide eviction trends</li>
<li>No action needed on your side - this is expected</li>
</ul>
</ol>
<ol>
<li><b>Too few replicas</b></li>
<ul>
<li>When one pod evicts, affects larger % of capacity</li>
<li><b>Fix:</b> Increase replicas (minimum 3 for spot workloads)</li>
</ul>
</ol>
<ol>
<li><b>Improper readiness probe</b></li>
<ul>
<li>Pods marked Ready too quickly, receive traffic before fully initialized</li>
<li><b>Fix:</b> Tune readiness probe timing</li>
<pre class="yaml"><code>
   readinessProbe:

     initialDelaySeconds: 10  # Increase if app slow to start

     periodSeconds: 5

</code></pre>
</ul>
</ol>
<p>---</p>
<h3>Issue 3: Application Errors During Eviction</h3>
<p><b>Symptom:</b> Spike in 5xx errors or timeouts when spot nodes evicted</p>
<p><b>Root Cause:</b> Application not shutting down gracefully</p>
<p><b>Fix Checklist:</b></p>
<ul>
<li>[ ] preStop hook implemented with adequate sleep time</li>
<li>[ ] terminationGracePeriodSeconds ≥ preStop sleep + 5 seconds</li>
<li>[ ] Readiness probe marks pod NotReady quickly (low failureThreshold)</li>
<li>[ ] Application handles SIGTERM signal</li>
<li>[ ] In-flight requests complete before shutdown</li>
</ul>
<p><b>Testing:</b></p>
<pre class="bash"><code>
# Send traffic while terminating pod

kubectl run -it --rm load-gen --image=busybox -- sh -c \

  &quot;while true; do wget -q -O- http://my-api; sleep 0.1; done&quot; &amp;



# Terminate a pod

kubectl delete pod &lt;pod-name&gt;



# Check for errors in load-gen output

# Expected: No errors or very minimal (&lt;0.1%)

</code></pre>
<p>---</p>
<h2>CI/CD Integration</h2>
<h3>GitHub Actions Example</h3>
<pre class="yaml"><code>
# .github/workflows/deploy.yml

name: Deploy to AKS



on:

  push:

    branches: [main]



jobs:

  deploy:

    runs-on: ubuntu-latest

    steps:

      - uses: actions/checkout@v3



      - name: Set up kubectl

        uses: azure/setup-kubectl@v3



      - name: Azure Login

        uses: azure/login@v1

        with:

          creds: ${{ secrets.AZURE_CREDENTIALS }}



      - name: Get AKS credentials

        run: |

          az aks get-credentials \

            --resource-group rg-aks-prod \

            --name aks-prod



      - name: Validate spot compatibility

        run: |

          # Ensure deployment has spot toleration

          if ! grep -q &quot;kubernetes.azure.com/scalesetpriority&quot; k8s/deployment.yaml; then

            echo &quot;WARNING: Deployment missing spot toleration&quot;

            echo &quot;Add spot toleration for cost savings&quot;

            # Don&#x27;t fail, just warn

          fi



      - name: Deploy

        run: |

          kubectl apply -f k8s/ --namespace=production

          kubectl rollout status deployment/my-api -n production --timeout=5m



      - name: Verify deployment

        run: |

          # Check if pods are on spot nodes

          SPOT_COUNT=$(kubectl get pods -n production -l app=my-api -o json | \

            jq &#x27;[.items[] | select(.spec.nodeName != null)] | length&#x27;)

          echo &quot;Pods on cluster: $SPOT_COUNT&quot;



          # It&#x27;s OK if not all on spot (might be on standard fallback)

          # Just report the distribution

</code></pre>
<p>---</p>
<h2>Helm Chart Integration</h2>
<p>If you use Helm, add these values:</p>
<pre class="yaml"><code>
# values.yaml

replicaCount: 6



spot:

  enabled: true  # Toggle spot support

  tolerations:

    - key: kubernetes.azure.com/scalesetpriority

      operator: Equal

      value: spot

      effect: NoSchedule



  affinity:

    nodeAffinity:

      preferredDuringSchedulingIgnoredDuringExecution:

        - weight: 100

          preference:

            matchExpressions:

              - key: kubernetes.azure.com/scalesetpriority

                operator: In

                values: [spot]



podDisruptionBudget:

  enabled: true

  minAvailable: 50%



gracefulShutdown:

  enabled: true

  preStopSleepSeconds: 25

  terminationGracePeriodSeconds: 35

</code></pre>
<pre class="yaml"><code>
# templates/deployment.yaml

{{- if .Values.spot.enabled }}

tolerations:

  {{- toYaml .Values.spot.tolerations | nindent 2 }}



affinity:

  {{- toYaml .Values.spot.affinity | nindent 2 }}

{{- end }}



{{- if .Values.gracefulShutdown.enabled }}

lifecycle:

  preStop:

    exec:

      command:

        - /bin/sh

        - -c

        - sleep {{ .Values.gracefulShutdown.preStopSleepSeconds }}



terminationGracePeriodSeconds: {{ .Values.gracefulShutdown.terminationGracePeriodSeconds }}

{{- end }}

</code></pre>
<p>---</p>
<h2>Best Practices Checklist</h2>
<h3>Before Deploying to Spot</h3>
<ul>
<li>[ ] Application is stateless OR has external state management</li>
<li>[ ] Minimum 3 replicas for production workloads</li>
<li>[ ] Graceful shutdown implemented (handles SIGTERM)</li>
<li>[ ] preStop hook with 25-second sleep</li>
<li>[ ] terminationGracePeriodSeconds ≥ 35 seconds</li>
<li>[ ] Readiness probe configured (fast to mark NotReady)</li>
<li>[ ] PodDisruptionBudget created (minAvailable: 50%)</li>
<li>[ ] Topology spread constraints added</li>
<li>[ ] Tested eviction scenario in dev environment</li>
<li>[ ] Application handles brief outages gracefully</li>
<li>[ ] No compliance restrictions (PCI/HIPAA/etc.)</li>
</ul>
<h3>Monitoring Your Spot Workloads</h3>
<pre class="bash"><code>
# Add these labels to your deployment for tracking

labels:

  cost-optimization: spot-preferred

  cost-center: your-team-name



# Platform team provides dashboards filtered by these labels

</code></pre>
<p>Access dashboards at: Grafana → AKS → Spot Adoption by Team</p>
<p>---</p>
<h2>Cost Visibility</h2>
<h3>How Much Am I Saving?</h3>
<p>Platform team provides per-namespace cost breakdown.</p>
<p><b>Example Report:</b></p>
<pre class=""><code>
Namespace: ecommerce-api

├─ Pods on Spot: 18 (75%)

├─ Pods on Standard: 6 (25%)

├─ Monthly Cost: $450

└─ Savings vs All Standard: $780 (63%)

</code></pre>
<p><b>Access:</b> Azure Cost Management → Tags → Filter by namespace</p>
<p>---</p>
<h2>Getting Help</h2>
<h3>Self-Service Resources</h3>
<table>
<tr><td>Resource</td><td>Link</td><td>Purpose</td></tr>
<tr><td>Spot Docs</td><td>[Link to internal wiki]</td><td>Detailed documentation</td></tr>
<tr><td>Deployment Templates</td><td>[Link to Git repo]</td><td>Copy-paste examples</td></tr>
<tr><td>Grafana Dashboards</td><td>[Link to Grafana]</td><td>Monitor your apps</td></tr>
<tr><td>Cost Explorer</td><td>[Link to Azure]</td><td>Track savings</td></tr>
<h3>Support Channels</h3>
<table>
<tr><td>Issue Type</td><td>Contact</td><td>Response Time</td></tr>
<tr><td>General Questions</td><td>#platform-engineering (Slack)</td><td>Best effort</td></tr>
<tr><td>Deployment Issues</td><td>#devops-support (Slack)</td><td>4 business hours</td></tr>
<tr><td>Incident (P1/P2)</td><td>#incident-response (Slack)</td><td>Immediate</td></tr>
<tr><td>Cost Questions</td><td>#finops (Slack)</td><td>24 hours</td></tr>
<h3>Office Hours</h3>
<p><b>Platform Engineering Office Hours:</b>  </p>
<p>Every Tuesday & Thursday, 2:00-3:00 PM  </p>
<p>Video: [Zoom Link]  </p>
<p>No agenda required - drop in with questions!</p>
<p>---</p>
<h2>FAQ</h2>
<p><b>Q: Will my app be less reliable on spot?</b>  </p>
<p>A: No, IF you follow best practices (3+ replicas, graceful shutdown, PDB). spot Just means pods reschedule occasionally.</p>
<p><b>Q: How often do spot evictions happen?</b>  </p>
<p>A: Averages 3-5% per month per node. With 3 diversified spot pools, simultaneous eviction is <1% probability.</p>
<p><b>Q: What if I forget the toleration?</b>  </p>
<p>A: Your app will only schedule on standard nodes - no savings, but no harm.</p>
<p><b>Q: Can I use spot for batch jobs?</b>  </p>
<p>A: Yes! Spot is PERFECT for batch jobs. Use Kubernetes Jobs or CronJobs with spot tolerations.</p>
<p><b>Q: What happens during spot eviction?</b>  </p>
<p>A:</p>
<ol>
<li>Azure sends 30-second eviction notice</li>
<li>Pod marked NotReady (traffic stops)</li>
<li>preStop hook runs (cleanup)</li>
<li>Pod terminated</li>
<li>New pod schedules on available node (spot or standard)</li>
<li>Total downtime per pod: ~30-60 seconds (but you have multiple replicas!)</li>
</ol>
<p><b>Q: Can I mix spot and standard in the same deployment?</b>  </p>
<p>A: Yes! That's exactly how it works. topology spread constraints distribute pods across both.</p>
<p><b>Q: Do I need to change my application code?</b>  </p>
<p>A: Only to add graceful shutdown (SIGTERM handling). This is good practice anyway!</p>
<p>---</p>
<h2>Migration Checklist</h2>
<h3>Migrating Existing Deployment to Spot</h3>
<pre class="bash"><code>
# 1. Backup current deployment

kubectl get deployment &lt;deployment-name&gt; -n &lt;namespace&gt; -o yaml &gt; backup.yaml



# 2. Add spot toleration, affinity, topology spread

# Edit your deployment YAML with template from above



# 3. Deploy to dev first

kubectl apply -f deployment.yaml --namespace=dev



# 4. Test eviction scenario (see &quot;Testing Your Application&quot; section)



# 5. Monitor for 1 week in dev



# 6. Deploy to staging

kubectl apply -f deployment.yaml --namespace=staging



# 7. Monitor for 1 week in staging



# 8. Deploy to production (gradual rollout)

kubectl apply -f deployment.yaml --namespace=production



# 9. Monitor cost savings

# Check Grafana dashboard after 1 month

</code></pre>
<p>---</p>
<p><b>Questions? Feedback?</b></p>
<p>This guide is maintained by the Platform Engineering team.  </p>
<p>Submit improvements via PR to: [git repo link]</p>
<p>Last Updated: 2026-01-12</p>
</body></html>